{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1\">Imports</a></span></li><li><span><a href=\"#Set-parameters-and-load-filenames\" data-toc-modified-id=\"Set-parameters-and-load-filenames-2\">Set parameters and load filenames</a></span></li><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-3\">Functions</a></span></li><li><span><a href=\"#Extract-data-from-files\" data-toc-modified-id=\"Extract-data-from-files-4\">Extract data from files</a></span></li><li><span><a href=\"#Cross-validation\" data-toc-modified-id=\"Cross-validation-5\">Cross-validation</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T18:43:04.640547Z",
     "start_time": "2020-07-01T18:43:00.082730Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os.path\n",
    "import random\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics \n",
    "from sklearn import tree, ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "import utils.bookdroputils as bd\n",
    "import sklearn.model_selection as model_selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set parameters and load filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T18:43:07.104961Z",
     "start_time": "2020-07-01T18:43:07.094988Z"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the dataset to use\n",
    "data_set = 'boardgames' # 'boardgames' or 'paperbacks'\n",
    "# Find directory for that dataset\n",
    "data_folder = os.path.join('data',data_set)\n",
    "\n",
    "# Collect list of all files\n",
    "file_list = [f for f in os.listdir(data_folder) if os.path.isfile(os.path.join(data_folder, f))]\n",
    "# Split list into 4 sets for cross-validation\n",
    "P, Q = train_test_split(file_list, test_size=0.5, random_state=111)\n",
    "A, B = train_test_split(P, test_size=0.5, random_state=222)\n",
    "C, D = train_test_split(Q, test_size=0.5, random_state=333)\n",
    "file_sets = [A, B, C, D]\n",
    "\n",
    "# Number of timepoints to search ahead for a price drop\n",
    "future = 60\n",
    "# Fraction of the price considered a 'drop'\n",
    "# E.g., 0.1 for a 10% price drop\n",
    "drop_frac = .1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T18:43:08.696708Z",
     "start_time": "2020-07-01T18:43:08.682744Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_feature_data(files, data_set, future, drop_frac, verbose=False):\n",
    "    # Store features and labels\n",
    "    X = []\n",
    "    Y = []\n",
    "    # Also store dollars spent and time waited for each strategy\n",
    "    dollars_spent = []\n",
    "    time_waited = []\n",
    "    \n",
    "    # Display messages when progress crosses this threshold\n",
    "    progress_threshold = 0\n",
    "    num_processed = 0\n",
    "    \n",
    "    # For each product\n",
    "    for file_name in files:\n",
    "        # Read file\n",
    "        df = pd.read_csv(os.path.join('data', data_set, file_name))\n",
    "        # Drop missing values\n",
    "        df.dropna(inplace=True)\n",
    "        # Convert prices to array\n",
    "        prices = np.array(df['price'])\n",
    "\n",
    "        # Sample data at 1-month intervals, starting at a random point in time\n",
    "        for k in range(\n",
    "                random.randint(0, 30) + 120 + 5, df.shape[0] - future - 30,\n",
    "                60):\n",
    "\n",
    "            # Extract price features\n",
    "            features = bd.compute_features(prices[:k + 1], drop_frac)\n",
    "\n",
    "            # Store the features\n",
    "            X.append(features)\n",
    "\n",
    "            # Store the class label\n",
    "            if np.any(prices[(k + 1):(k + future + 1)] < (1 - drop_frac) *\n",
    "                      prices[k]):\n",
    "                Y.append(1)\n",
    "            else:\n",
    "                Y.append(0)\n",
    "\n",
    "            # Extract the prices in the lookahead period\n",
    "            future_prices = prices[(k + 1):(k + future + 1)]\n",
    "\n",
    "            # Compute dollars spent and time waited for each strategy\n",
    "            if Y[-1] == 1:\n",
    "                idx_below = np.argwhere(future_prices < (1 - drop_frac) *\n",
    "                                        prices[k])[0].astype(int)[0]\n",
    "                bookdrop_price = future_prices[idx_below]\n",
    "                bookdrop_wait = idx_below + 1\n",
    "                tracker_price = future_prices[idx_below]\n",
    "                tracker_wait = idx_below + 1\n",
    "                perfect_price = future_prices[idx_below]\n",
    "                perfect_wait = idx_below + 1\n",
    "\n",
    "            else:\n",
    "                bookdrop_price = prices[k + future]\n",
    "                bookdrop_wait = future\n",
    "                tracker_price = prices[k + future]\n",
    "                tracker_wait = future\n",
    "                perfect_price = prices[k]\n",
    "                perfect_wait = 0\n",
    "\n",
    "            # Store the dollars spent\n",
    "            dollars_spent.append(\n",
    "                np.array([\n",
    "                    perfect_price, bookdrop_price, tracker_price, prices[k],\n",
    "                    prices[k + future]\n",
    "                ]))\n",
    "\n",
    "            # Store the time waited\n",
    "            time_waited.append(\n",
    "                np.array([perfect_wait, bookdrop_wait, tracker_wait]))\n",
    "\n",
    "        # Show progress\n",
    "        if verbose:\n",
    "            num_processed += 1\n",
    "            if num_processed / len(files) > progress_threshold:\n",
    "                print(str(round(progress_threshold * 100)) + '% done')\n",
    "                progress_threshold += .2\n",
    "            \n",
    "    return np.array(X), np.array(Y), np.array(dollars_spent), np.array(time_waited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T18:43:11.310722Z",
     "start_time": "2020-07-01T18:43:11.295761Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function to evaluate the performance of a model on a test set\n",
    "def evaluate_model(model, x_test, y_test, dollars_spent_test, time_waited_test, future):\n",
    "    # Make predictions on test set\n",
    "    y_pred = model.predict(x_test)\n",
    "    # Calculate accuracy\n",
    "    accuracy = 100 * sum(y_pred == y_test)/len(y_pred)\n",
    "    \n",
    "    # Compute errors for the confusion matrix\n",
    "    TN = np.sum(np.bitwise_and(y_test == 0, y_pred == 0))\n",
    "    FP = np.sum(np.bitwise_and(y_test == 0, y_pred == 1))\n",
    "    FN = np.sum(np.bitwise_and(y_test == 1, y_pred == 0))\n",
    "    TP = np.sum(np.bitwise_and(y_test == 1, y_pred == 1))\n",
    "    \n",
    "    # Calculate precision\n",
    "    precision = TP / (TP + FP)\n",
    "    # Calculate recall\n",
    "    recall = TP / (TP + FN)\n",
    "    \n",
    "    # Compute spending for each strategy\n",
    "    cost_perfect = np.sum(dollars_spent_test[:, 0])\n",
    "    cost_bookdrop = np.sum(dollars_spent_test[y_pred == 0, 3]) + np.sum(\n",
    "        dollars_spent_test[y_pred == 1, 1])\n",
    "    cost_tracker = np.sum(dollars_spent_test[:, 2])\n",
    "    cost_now = np.sum(dollars_spent_test[:, 3])\n",
    "    cost_wait_only = np.sum(dollars_spent_test[:, 4])\n",
    "    \n",
    "    # Spending for each strategy\n",
    "    cost_perfect = dollars_spent_test[:, 0]\n",
    "    cost_bookdrop = dollars_spent_test[np.arange(len(dollars_spent_test)), [3 if y == 0 else 1 for y in y_pred]]\n",
    "    cost_tracker = dollars_spent_test[:, 2]\n",
    "    cost_now = dollars_spent_test[:, 3]\n",
    "    cost_wait_only = dollars_spent_test[:, 4]\n",
    "    \n",
    "    cost_perfect = sum(cost_perfect)\n",
    "    cost_bookdrop = sum(cost_bookdrop)\n",
    "    cost_tracker = sum(cost_tracker)\n",
    "    cost_now = sum(cost_now)\n",
    "    cost_wait_only = sum(cost_wait_only)\n",
    "    \n",
    "    # Time waited for each strategy\n",
    "    lag_perfect = time_waited_test[:, 0]\n",
    "    lag_bookdrop = np.append(time_waited_test[y_pred == 1, 1],np.zeros((sum(y_pred==0),1)))\n",
    "    lag_tracker = time_waited_test[:, 2]\n",
    "    \n",
    "    # Median cost savings for each strategy\n",
    "    perfect_savings = 100 * (1 - np.median(cost_perfect / cost_now))\n",
    "    bookdrop_savings = 100 * (1 - np.median(cost_bookdrop / cost_now))\n",
    "    tracker_savings = 100 * (1 - np.median(cost_tracker / cost_now))\n",
    "    wait_only_savings = 100 * (1 - np.median(cost_wait_only / cost_now))\n",
    "      \n",
    "    # Efficiency\n",
    "    bookdrop_efficiency = bookdrop_savings / perfect_savings\n",
    "    tracker_efficiency = tracker_savings / perfect_savings\n",
    "    wait_only_efficiency = wait_only_savings / perfect_savings\n",
    "    \n",
    "    # Days waited\n",
    "    perfect_days = np.mean(lag_perfect) / 2\n",
    "    bookdrop_days = np.mean(lag_bookdrop) / 2\n",
    "    tracker_days = np.mean(lag_tracker) / 2\n",
    "    wait_only_days = future / 2\n",
    "     \n",
    "    # Time saved\n",
    "    perfect_time_savings = 100 - 100 * (perfect_days / wait_only_days)\n",
    "    bookdrop_time_savings = 100 - 100 * (bookdrop_days / wait_only_days)\n",
    "    \n",
    "    simulation_results = pd.DataFrame(\n",
    "        [[perfect_savings, 1, perfect_days,perfect_time_savings],\n",
    "         [bookdrop_savings, bookdrop_efficiency, bookdrop_days, bookdrop_time_savings],\n",
    "         [tracker_savings,tracker_efficiency,tracker_days,''],\n",
    "         [wait_only_savings,wait_only_efficiency,wait_only_days,'']\n",
    "        ],\n",
    "        columns=['median_savings', 'efficiency', 'mean_wait_time', 'time_saved'],\n",
    "        index=['Perfect','BookDrop','Tracker only','Wait'])\n",
    "    \n",
    "    return accuracy, precision, recall, simulation_results, TP, FP, TN, FN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T18:43:16.818034Z",
     "start_time": "2020-07-01T18:43:14.594943Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "random.seed(99)\n",
    "np.random.seed(99)\n",
    "\n",
    "# Initialize data storage\n",
    "X = []\n",
    "Y = []\n",
    "dollars_spent = []\n",
    "time_waited = []\n",
    "\n",
    "# Collect data from each file set\n",
    "for idx, S in enumerate(file_sets):\n",
    "    X_S, Y_S, dollars_spent_S, time_waited_S = extract_feature_data(S, data_set, future, drop_frac)\n",
    "    X.append(X_S)\n",
    "    Y.append(Y_S)\n",
    "    dollars_spent.append(dollars_spent_S)\n",
    "    time_waited.append(time_waited_S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T18:47:41.333553Z",
     "start_time": "2020-07-01T18:47:36.162254Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize list of dataframes\n",
    "results_list = []\n",
    "\n",
    "# Define parameters for the random forest model\n",
    "parameters = {\n",
    "    'bootstrap': True,\n",
    "    'max_depth': 10,\n",
    "    'max_features': 'sqrt',\n",
    "    'min_samples_leaf': 4,\n",
    "    'min_samples_split': 4,\n",
    "    'n_estimators': 300\n",
    "}\n",
    "\n",
    "# Calculate cross-validated metrics\n",
    "for fold in range(4):\n",
    "    # Choose test set\n",
    "    X_test = X[fold]\n",
    "    Y_test = Y[fold]\n",
    "    dollars_spent_test = dollars_spent[fold]\n",
    "    time_waited_test = time_waited[fold]\n",
    "    \n",
    "    # Build training set\n",
    "    train_idx = list(set(range(4)) - set([fold]))\n",
    "    X_train = X[train_idx[0]]\n",
    "    Y_train = Y[train_idx[0]]\n",
    "    for i in range(1,3):\n",
    "        X_train = np.append(X_train, X[train_idx[i]], axis=0)\n",
    "        Y_train = np.append(Y_train, Y[train_idx[i]], axis=0)\n",
    "    \n",
    "    # Train the model\n",
    "    RF_model = BalancedRandomForestClassifier(**parameters)\n",
    "    RF_model.fit(X_train, Y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy, precision, recall, simulation_results, TP, FP, TN, FN = \\\n",
    "        evaluate_model(RF_model, X_test, Y_test, dollars_spent_test, time_waited_test, future)\n",
    "    results_list.append(simulation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T18:56:11.472328Z",
     "start_time": "2020-07-01T18:56:11.459363Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>median_savings</th>\n",
       "      <th>efficiency</th>\n",
       "      <th>mean_wait_time</th>\n",
       "      <th>time_saved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Perfect</th>\n",
       "      <td>5.84232</td>\n",
       "      <td>1</td>\n",
       "      <td>3.79802</td>\n",
       "      <td>87.3399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BookDrop</th>\n",
       "      <td>3.29354</td>\n",
       "      <td>0.565333</td>\n",
       "      <td>8.91934</td>\n",
       "      <td>70.2689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tracker only</th>\n",
       "      <td>3.28814</td>\n",
       "      <td>0.560374</td>\n",
       "      <td>24.6831</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wait</th>\n",
       "      <td>-0.00467501</td>\n",
       "      <td>-0.00145954</td>\n",
       "      <td>30</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             median_savings  efficiency mean_wait_time time_saved\n",
       "Perfect             5.84232           1        3.79802    87.3399\n",
       "BookDrop            3.29354    0.565333        8.91934    70.2689\n",
       "Tracker only        3.28814    0.560374        24.6831           \n",
       "Wait            -0.00467501 -0.00145954             30           "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display cross-validated metrics\n",
    "\n",
    "# Average across folds\n",
    "results_cv = np.array(results_list[0])\n",
    "results_cv[2:4,3] = 0 # handle blank cells\n",
    "for i in range(1,4):\n",
    "    temp = np.array(results_list[i])\n",
    "    temp[2:4,3] = 0\n",
    "    results_cv += temp\n",
    "results_cv = results_cv / 4\n",
    "results_cv[2:4,3] = ''\n",
    "\n",
    "# Display results\n",
    "pd.DataFrame(\n",
    "    results_cv,\n",
    "    columns=['median_savings', 'efficiency', 'mean_wait_time', 'time_saved'],\n",
    "    index=['Perfect','BookDrop','Tracker only','Wait'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
